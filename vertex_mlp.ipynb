{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03bfe95b-eaf1-4f80-9ba2-2f79fd9fe79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8efdb27a-a6c1-4f54-bb2c-8470ba8feb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>px1</th>\n",
       "      <th>py1</th>\n",
       "      <th>pz1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>px2</th>\n",
       "      <th>py2</th>\n",
       "      <th>pz2</th>\n",
       "      <th>q2</th>\n",
       "      <th>vtx</th>\n",
       "      <th>vty</th>\n",
       "      <th>vtz</th>\n",
       "      <th>vpx</th>\n",
       "      <th>vpy</th>\n",
       "      <th>vpz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.03680</td>\n",
       "      <td>9.14611</td>\n",
       "      <td>594.467</td>\n",
       "      <td>2.227900</td>\n",
       "      <td>0.682157</td>\n",
       "      <td>40.16110</td>\n",
       "      <td>96.92970</td>\n",
       "      <td>31.9730</td>\n",
       "      <td>1936.99</td>\n",
       "      <td>2.612100</td>\n",
       "      <td>0.682219</td>\n",
       "      <td>40.11380</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.094969</td>\n",
       "      <td>-0.173778</td>\n",
       "      <td>37.7394</td>\n",
       "      <td>-0.718459</td>\n",
       "      <td>0.855686</td>\n",
       "      <td>49.2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-15.12700</td>\n",
       "      <td>-25.56580</td>\n",
       "      <td>594.718</td>\n",
       "      <td>-0.423330</td>\n",
       "      <td>-2.644100</td>\n",
       "      <td>55.02350</td>\n",
       "      <td>-19.27280</td>\n",
       "      <td>-88.2689</td>\n",
       "      <td>1899.93</td>\n",
       "      <td>-0.035456</td>\n",
       "      <td>-2.641810</td>\n",
       "      <td>55.00070</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.873625</td>\n",
       "      <td>0.590022</td>\n",
       "      <td>33.2498</td>\n",
       "      <td>-3.135350</td>\n",
       "      <td>-3.081690</td>\n",
       "      <td>62.5317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-4.48184</td>\n",
       "      <td>-5.02827</td>\n",
       "      <td>594.616</td>\n",
       "      <td>0.569838</td>\n",
       "      <td>-0.706143</td>\n",
       "      <td>72.74330</td>\n",
       "      <td>10.18230</td>\n",
       "      <td>-17.6988</td>\n",
       "      <td>1899.86</td>\n",
       "      <td>0.956272</td>\n",
       "      <td>-0.705887</td>\n",
       "      <td>72.71820</td>\n",
       "      <td>1</td>\n",
       "      <td>0.363496</td>\n",
       "      <td>0.541102</td>\n",
       "      <td>27.1000</td>\n",
       "      <td>-2.388700</td>\n",
       "      <td>-0.748944</td>\n",
       "      <td>80.4553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-45.93980</td>\n",
       "      <td>18.25010</td>\n",
       "      <td>594.912</td>\n",
       "      <td>-0.013079</td>\n",
       "      <td>0.509187</td>\n",
       "      <td>9.29352</td>\n",
       "      <td>-11.46980</td>\n",
       "      <td>91.4206</td>\n",
       "      <td>1936.73</td>\n",
       "      <td>0.374477</td>\n",
       "      <td>0.506969</td>\n",
       "      <td>9.30575</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.047285</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>56.4399</td>\n",
       "      <td>-3.557140</td>\n",
       "      <td>0.214992</td>\n",
       "      <td>18.2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-19.95970</td>\n",
       "      <td>28.69740</td>\n",
       "      <td>594.706</td>\n",
       "      <td>0.195606</td>\n",
       "      <td>1.114430</td>\n",
       "      <td>22.93230</td>\n",
       "      <td>6.27534</td>\n",
       "      <td>93.8775</td>\n",
       "      <td>1936.75</td>\n",
       "      <td>0.583209</td>\n",
       "      <td>1.111620</td>\n",
       "      <td>22.90280</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.263670</td>\n",
       "      <td>1.339230</td>\n",
       "      <td>41.8576</td>\n",
       "      <td>-2.991010</td>\n",
       "      <td>1.618660</td>\n",
       "      <td>30.3003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   q1        x1        y1       z1       px1       py1       pz1        x2  \\\n",
       "0   1  14.03680   9.14611  594.467  2.227900  0.682157  40.16110  96.92970   \n",
       "1   1 -15.12700 -25.56580  594.718 -0.423330 -2.644100  55.02350 -19.27280   \n",
       "2   1  -4.48184  -5.02827  594.616  0.569838 -0.706143  72.74330  10.18230   \n",
       "3   1 -45.93980  18.25010  594.912 -0.013079  0.509187   9.29352 -11.46980   \n",
       "4   1 -19.95970  28.69740  594.706  0.195606  1.114430  22.93230   6.27534   \n",
       "\n",
       "        y2       z2       px2       py2       pz2  q2       vtx       vty  \\\n",
       "0  31.9730  1936.99  2.612100  0.682219  40.11380   1 -0.094969 -0.173778   \n",
       "1 -88.2689  1899.93 -0.035456 -2.641810  55.00070   1 -0.873625  0.590022   \n",
       "2 -17.6988  1899.86  0.956272 -0.705887  72.71820   1  0.363496  0.541102   \n",
       "3  91.4206  1936.73  0.374477  0.506969   9.30575   1 -0.047285  0.010607   \n",
       "4  93.8775  1936.75  0.583209  1.111620  22.90280   1 -0.263670  1.339230   \n",
       "\n",
       "       vtz       vpx       vpy      vpz  \n",
       "0  37.7394 -0.718459  0.855686  49.2060  \n",
       "1  33.2498 -3.135350 -3.081690  62.5317  \n",
       "2  27.1000 -2.388700 -0.748944  80.4553  \n",
       "3  56.4399 -3.557140  0.214992  18.2017  \n",
       "4  41.8576 -2.991010  1.618660  30.3003  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "data = pd.read_csv('data/raw/events-20k.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "207fff90-50fb-4b46-992c-f093f2bec002",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[['q1', 'x1', 'y1', 'z1', 'px1', 'py1', 'pz1', 'x2', 'y2', 'z2', 'px2', 'py2', 'pz2']].to_numpy(), data[['vtz']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cfbb391-d68e-486c-96ca-bcc1dbda4cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25380, 13), (25380, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb909a7-5c57-44ae-8b1a-0962a4e6d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:\n",
      "(15228, 13)\n",
      "(15228, 1)\n",
      "validation:\n",
      "(5076, 13)\n",
      "(5076, 1)\n",
      "test:\n",
      "(5076, 13)\n",
      "(5076, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25)\n",
    "\n",
    "print('training:')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print('validation:')\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print('test:')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb580e1-5a53-4fd7-a90e-fd7ac187bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scale the input\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d72f599-f278-4e9e-96c7-74d7781e99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, let's construct the model\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "\n",
    "class vertexFinder(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(vertexFinder, self).__init__()\n",
    "        # Let's define our layers here.\n",
    "        self.fc1 = torch.nn.Linear(in_features, 16, bias=True) # Define the first layer (input: in_features and 32 outputs)\n",
    "        self.fc2 = torch.nn.Linear(16, 3, bias=True) # Define the second hidden layer \n",
    "        self.fc3 = torch.nn.Linear(3, 3, bias=True) # Define the third hidden layer \n",
    "        self.fc4 = torch.nn.Linear(3, out_features, bias=True) # Define the output layer \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Let's define out forward pass\n",
    "        x = F.relu(self.fc1(x)) # Pass through the first layer and relu activation\n",
    "        x = F.relu(self.fc2(x)) # Now through the second\n",
    "        x = F.relu(self.fc3(x)) # And third\n",
    "        x = F.relu(self.fc4(x)) # Our output should be linear\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bde5ee6-8b64-4997-b0f3-93ec47e79f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = vertexFinder(13, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da50ff83-ef66-4a0b-bba9-d0af12d96701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertexFinder(\n",
      "  (fc1): Linear(in_features=13, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=3, bias=True)\n",
      "  (fc3): Linear(in_features=3, out_features=3, bias=True)\n",
      "  (fc4): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f6d9c74-ccee-4875-b030-0a3027993bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(net.fc3.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "290eb03e-ee77-485b-9f8c-a953c046d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_scripted = torch.jit.script(net) \n",
    "# model_scripted.save('myVertexFinder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e935256a-1704-4f04-adcd-b2a20090804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's visualize the computational graph\n",
    "\n",
    "# from torchviz import make_dot\n",
    "\n",
    "# net.eval()\n",
    "# yhat = net(torch.zeros(1, 13))\n",
    "# make_dot(yhat, params=dict(list(net.named_parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "673fc188-bc6b-49c1-931c-8c8fe56fe1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(torch.Tensor(X_val), torch.Tensor(y_val))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebf5b1c8-ab08-444e-87be-55c76c6e7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':1.5f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{avg' + self.fmt + '} ({name})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf9b5641-70c3-4406-afc4-69635a39fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "585e85e0-06ed-4f5f-8dad-3d8fc3f4f66e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (60) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate(loss_batch\u001b[38;5;241m.\u001b[39mdata)\n\u001b[1;32m     27\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m (targets \u001b[38;5;241m==\u001b[39m outputs)\n\u001b[0;32m---> 28\u001b[0m \u001b[43macc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccuracy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Compute the gradients\u001b[39;00m\n\u001b[1;32m     32\u001b[0m loss_batch\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn [14], line 14\u001b[0m, in \u001b[0;36mAverageMeter.update\u001b[0;34m(self, val, n)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, val, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m val \u001b[38;5;241m*\u001b[39m n\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m n\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (60) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "acc, loss = AverageMeter('Accuracy'), AverageMeter('Loss')\n",
    "train_loss, val_acc, val_loss = [], [], []\n",
    "\n",
    "# Iterate over the dataset <epochs> times\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Set the model to training mode\n",
    "    net.train()\n",
    "    # Reset our meters\n",
    "    loss.reset()\n",
    "    acc.reset()\n",
    "\n",
    "    # Iterate over batches\n",
    "    for inputs, targets in train_dataloader:\n",
    "\n",
    "        # Remove previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Feed forward the input\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "\n",
    "        # Compute the loss and accuracy\n",
    "        loss_batch = criterion(outputs, targets)\n",
    "        loss.update(loss_batch.data)\n",
    "        \n",
    "        accuracy = (targets == outputs).sum()\n",
    "        acc.update(accuracy.data)\n",
    "        \n",
    "\n",
    "        # Compute the gradients\n",
    "        loss_batch.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss.append(loss.avg)\n",
    "    \n",
    "    print(\"Training : Epoch , Loss, Acc : {}, {}, {}\".format(epoch+1, loss.avg, acc.avg))\n",
    "    \n",
    "    # Validation for each epoch\n",
    "    net.eval()\n",
    "    loss.reset()\n",
    "    acc.reset()\n",
    "\n",
    "    for inputs, targets in val_dataloader:\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss_batch = criterion(outputs, targets)\n",
    "        loss.update(loss_batch.data)\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "        accuracy = (torch.argmax(targets, dim=-1) == preds).sum() / len(targets)\n",
    "        acc.update(accuracy.data)\n",
    "        \n",
    "\n",
    "    val_loss.append(loss.avg)\n",
    "    val_acc.append(acc.avg)\n",
    "    \n",
    "    print(\"Validate : Epoch , Loss, Acc : {}, {}, {}\".format(epoch+1, loss.avg, acc.avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c7d361-fb37-4d72-80ba-ad5f5d36b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "\n",
    "plt.style.use(hep.style.ROOT)\n",
    "\n",
    "# Let's draw loss and accuracy for the training and validation\n",
    "\n",
    "def draw_loss(data_train, data_val, data_acc, label=\"Loss\"):\n",
    "    \"\"\"Plots the training and validation loss\"\"\"\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 5))\n",
    "    ax1.set_xlabel(\"Epoch\", horizontalalignment='right', x=1.0)\n",
    "    ax1.set_ylabel(\"Loss\", horizontalalignment='right', y=1.0)\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.tick_params(axis='y', labelcolor='red')\n",
    "    ax1.plot(data_train,\n",
    "             color='red',\n",
    "             label='Training loss')\n",
    "    ax1.plot(data_val,\n",
    "             color='blue',\n",
    "             label='Validation loss')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Accuracy', color='black')\n",
    "    ax2.tick_params(axis='y', labelcolor='black')\n",
    "    ax2.plot(data_acc,\n",
    "             color='green',\n",
    "             label='Accuracy')\n",
    "    ax1.legend(loc='lower left')\n",
    "    ax2.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "draw_loss(train_loss, val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc1737-e902-47ff-96dd-1ed947258fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = net(torch.tensor(X_test).unsqueeze(0).float())\n",
    "\n",
    "print(\"Accuracy for the test set: {0:.2f}\".format(\n",
    "    accuracy_score(\n",
    "        np.argmax(y_test, axis=1),\n",
    "        torch.argmax(y_pred, dim=-1).squeeze().numpy())\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef5505-dde2-45bb-8b19-f9a7471fb048",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_pred.detach().numpy().squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df98d35-0a58-4ad1-8a0f-8078e17b2810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
