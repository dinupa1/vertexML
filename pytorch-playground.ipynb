{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ed7cb-d24f-4ce5-b7b7-ab97c2f05d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "\n",
    "# hep.style.use('ROOT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a5c531-109b-4aae-aa70-af02733d1fe3",
   "metadata": {},
   "source": [
    "# Tagging using Custom Build NN with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe422f4-bb9e-4291-b574-0a98eb8215ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(z: float)->int:\n",
    "    \"\"\"\n",
    "    Add labels according to the z vertex positon\n",
    "    \"\"\"\n",
    "    if -800.0 < z and z < -500.0:\n",
    "        return 0 # collimeter\n",
    "    if -500.0 < z and z < -305.0:\n",
    "        return 1 # air1\n",
    "    if -305.0 < z and z < -295.0:\n",
    "        return 2 # target\n",
    "    if -295.0 < z and z < 0.0:\n",
    "        return 3 # air2\n",
    "    if 0.0 < z and z < 250.0:\n",
    "        return 4 # beam dump\n",
    "    else:\n",
    "        return -99 # some error check the conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e6bcc7-f87a-48d0-bf10-e746f9e28874",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('events-200k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891da5ed-ba5b-4d3f-8614-c70d6f797c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_id = df['vtz'].apply(add_labels).to_numpy()\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.hist(hot_id, bins=5, range=[-0.5, 4.5], histtype='step')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('hot_id')\n",
    "plt.ylabel('counts')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720031d2-f4ea-4fd9-a3f0-61ba81d2572d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['q1', 'x1', 'y1', 'z1', 'x2', 'y2', 'z2', 'px1', 'py1', 'pz1', 'px2', 'py2', 'pz2']].to_numpy()\n",
    "y = df[['vtx', 'vty', 'vtz', 'vpx', 'vpy', 'vpz']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa482f-5cf7-40f9-8948-8139f5c76e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "hot_id = ohe.fit_transform(hot_id.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac84121-2231-4a6b-9412-2086f036d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train, validate test split\n",
    "X_train_val, X_test, y_train_val, y_test, hotid_train_val, hotid_test = train_test_split(X, y, hot_id, test_size=0.2)\n",
    "X_train, X_valid, y_train, y_valid, hotid_train, hotid_valid = train_test_split(X_train_val, y_train_val, hotid_train_val, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c596a4-385b-48ff-a859-cfea64342ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647f771-e063-4a35-ae10-e933d4998d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "\n",
    "class vertexTag(torch.nn.Module):\n",
    "    def __init__(self, in_features: int=13, out_features: int=5, hidden_dim: int=64):\n",
    "        super(vertexTag, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(in_features, hidden_dim, bias=True)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "        self.fc3 = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "        # self.fc4 = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "        self.fc5 = torch.nn.Linear(hidden_dim, out_features, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # x = F.relu(self.fc4(x))\n",
    "        # x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7359f60c-7b84-4d75-8fa6-81c12387b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class vertexReg(torch.nn.Module):\n",
    "    def __init__(self, in_features: int=13, out_features: int=6, hidden_dim: int=32):\n",
    "        super(vertexReg, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(in_features, hidden_dim, bias=True)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "        self.fc3 = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "        self.fc4 = torch.nn.Linear(hidden_dim, hidden_dim, bias=True)\n",
    "        self.fc5 = torch.nn.Linear(hidden_dim, out_features, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        # x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66a2054-cf02-4da6-81de-c5d909a04271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class vertexMLP(torch.nn.Module):\n",
    "    def __init__(self, in_features: int=13, hotid_dim: int=5, vert_dim: int=6, hidden_dim1: int=64, hidden_dim2: int=64):\n",
    "        super(vertexMLP, self).__init__()\n",
    "        self.fc1 = vertexTag(in_features, hotid_dim, hidden_dim1)\n",
    "        self.fc2 = vertexReg(in_features+hotid_dim, vert_dim, hidden_dim2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pred_hotid = self.fc1(x)\n",
    "        pred_vert = self.fc2(torch.cat([x, pred_hotid], axis=-1))\n",
    "        return pred_hotid, pred_vert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ce69a8-62db-4ffb-9f01-7486a6770a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = vertexMLP(hidden_dim1=32, hidden_dim2=32)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5650b75-64dc-4c9b-b3ad-e2c862ca7c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train), torch.Tensor(hotid_train))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(torch.Tensor(X_valid), torch.Tensor(y_valid), torch.Tensor(hotid_valid))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590c4cb-3ccc-4c5e-9826-005196d07071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':1.5f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "    def __str__(self):\n",
    "        fmtstr = '{avg' + self.fmt + '} ({name})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9b23e-d953-4a6b-837d-07413c82aad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_criterion = torch.nn.CrossEntropyLoss()\n",
    "reg_criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5.0e-04, weight_decay=1.0e-05)\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c1e1c-f17e-498a-9dfe-b5ec34ba38c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tag_acc, tag_loss = AverageMeter('TagAccuracy'), AverageMeter('TagLoss')\n",
    "reg_acc, reg_loss = AverageMeter('RegAccuracy'), AverageMeter('RegLoss')\n",
    "tag_train_loss, tag_val_acc, tag_val_loss = [], [], []\n",
    "reg_train_loss, reg_val_acc, reg_val_loss = [], [], []\n",
    "\n",
    "# Iterate over the dataset <epochs> times\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    alpha = 5.0e-04\n",
    "\n",
    "    # Set the model to training mode\n",
    "    net.train()\n",
    "    # Reset our meters\n",
    "    tag_loss.reset()\n",
    "    tag_acc.reset()\n",
    "    reg_loss.reset()\n",
    "\n",
    "    # Iterate over batches\n",
    "    for inputs, targets, hot_id in train_dataloader:\n",
    "\n",
    "        # Remove previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Feed forward the input\n",
    "        pred_hotid, pred_vtx = net(inputs)\n",
    "\n",
    "        # Compute the loss and accuracy\n",
    "        tag_loss_batch = tag_criterion(pred_hotid, hot_id)\n",
    "        tag_loss.update(tag_loss_batch.data)\n",
    "        \n",
    "        preds = torch.argmax(pred_hotid, dim=-1)\n",
    "        accuracy = (torch.argmax(hot_id, dim=-1) == preds).sum() / len(hot_id)\n",
    "        tag_acc.update(accuracy.data)\n",
    "        \n",
    "        # define some masks\n",
    "        # msk = (preds != 0) & (torch.argmax(targets[:, 6:], dim=-1) == preds)\n",
    "        \n",
    "        reg_loss_batch = reg_criterion(pred_vtx, targets)\n",
    "        reg_loss.update(reg_loss_batch.data)\n",
    "        \n",
    "        total_loss_batch = tag_loss_batch + alpha* reg_loss_batch\n",
    "\n",
    "        # Compute the gradients\n",
    "        total_loss_batch.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    tag_train_loss.append(tag_loss.avg)\n",
    "    reg_train_loss.append(reg_loss.avg)\n",
    "    \n",
    "    # Validation for each epoch\n",
    "    net.eval()\n",
    "    tag_loss.reset()\n",
    "    tag_acc.reset()\n",
    "    reg_loss.reset()\n",
    "\n",
    "    for inputs, targets, hot_id in val_dataloader:\n",
    "\n",
    "        pred_hotid, pred_vtx = net(inputs)\n",
    "\n",
    "        tag_loss_batch = tag_criterion(pred_hotid, hot_id)\n",
    "        tag_loss.update(tag_loss_batch.data)\n",
    "\n",
    "        preds = torch.argmax(pred_hotid, dim=-1)\n",
    "        accuracy = (torch.argmax(hot_id, dim=-1) == preds).sum() / len(hot_id)\n",
    "        tag_acc.update(accuracy.data)\n",
    "        \n",
    "        # define some masks\n",
    "        # msk = (preds != 0) & (torch.argmax(hot_id, dim=-1) == preds)\n",
    "        \n",
    "        # reg_loss_batch =reg_criterion(pred_vtx[msk], targets[msk])\n",
    "        reg_loss_batch =reg_criterion(pred_vtx, targets)\n",
    "        reg_loss.update(reg_loss_batch.data)\n",
    "        \n",
    "        # total_loss_batch = tag_loss_batch + alpha* reg_loss_batch\n",
    "\n",
    "    tag_val_loss.append(tag_loss.avg)\n",
    "    tag_val_acc.append(tag_acc.avg)\n",
    "    reg_val_loss.append(reg_loss.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101032e2-86aa-4f06-8279-5349a481939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_loss(data_train, data_val, data_acc, label=\"Loss\"):\n",
    "    \"\"\"Plots the training and validation loss\"\"\"\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 5))\n",
    "    ax1.set_xlabel(\"Epoch\", horizontalalignment='right', x=1.0)\n",
    "    ax1.set_ylabel(\"Loss\", horizontalalignment='right', y=1.0)\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.tick_params(axis='y', labelcolor='red')\n",
    "    ax1.plot(data_train,\n",
    "             color='red',\n",
    "             label='Training loss')\n",
    "    ax1.plot(data_val,\n",
    "             color='blue',\n",
    "             label='Validation loss')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Accuracy', color='black')\n",
    "    ax2.tick_params(axis='y', labelcolor='black')\n",
    "    ax2.plot(data_acc,\n",
    "             color='green',\n",
    "             label='Accuracy')\n",
    "    ax1.legend(loc='lower left')\n",
    "    ax2.legend(loc='upper left')\n",
    "    # plt.tight_layout()\n",
    "    plt.savefig('imgs/cls-loss.png')\n",
    "    plt.show()\n",
    "\n",
    "draw_loss(tag_train_loss, tag_val_loss, tag_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d1c0c0-91df-43cd-9c34-9f1bfa957063",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(reg_train_loss, label='Training loss')\n",
    "plt.plot(reg_val_loss, label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "# plt.tight_layout()\n",
    "plt.savefig('imgs/reg-loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5295952-5a68-4b80-be41-052f60712f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_hotid, y_pred = net(torch.tensor(X_test).unsqueeze(0).float())\n",
    "\n",
    "print(\"Accuracy for the test set: {0:.4f}\".format(\n",
    "    accuracy_score(\n",
    "        np.argmax(hotid_test, axis=1),\n",
    "        torch.argmax(pred_hotid, dim=-1).squeeze().numpy())\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302e8736-2ab9-40a9-aac8-88f1436f93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_roc(y_test, y_pred, labels):\n",
    "    for x in range(5):        \n",
    "        fpr, tpr, _ = roc_curve(y_test[:, x], y_pred[:, x])\n",
    "        plt.plot(fpr, tpr, label='{0} tagger, AUC = {1:.1f}'.format(labels[0][x], auc(fpr, tpr)*100.), linestyle='-')\n",
    "    # plt.semilogy()\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive\")\n",
    "    # plt.ylim(0.001, 1)\n",
    "    # plt.grid(True)\n",
    "    plt.legend(loc='lower right')  \n",
    "    \n",
    "plt.figure(figsize=(5, 5))\n",
    "plot_roc(hotid_test, pred_hotid.squeeze().detach().numpy(), ohe.categories_)\n",
    "plt.savefig('imgs/roc-curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21910e0-033b-4cb5-b1b8-659844cf2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_hotid = torch.argmax(pred_hotid, dim=-1).squeeze().detach().numpy()\n",
    "hotid_test = np.argmax(hotid_test, axis=1)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.hist(hotid_test, histtype='step', bins=5, range=(-0.5, 4.5), label='test')\n",
    "plt.hist(pred_hotid, histtype='step', bins=5, range=(-0.5, 4.5), label='pred')\n",
    "plt.xlabel('hot id')\n",
    "plt.ylabel('counts')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('imgs/cls-hot-id.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd8b01-9c9c-4370-8219-34aad2426496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(hotid_test, pred_hotid, labels=ohe.categories_[0])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=ohe.categories_[0])\n",
    "disp.plot()\n",
    "# disp.invert_yaxis()\n",
    "plt.savefig('imgs/cls-cm.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9d263-b6f1-42af-aa4e-a5aff9815b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, a, mu, sigma):\n",
    "    frac1 = (x - mu)* (x - mu)\n",
    "    frac2 = 2* sigma* sigma\n",
    "    return a* np.exp(-frac1/frac2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1974bea-3bc2-4784-bf11-246993e6da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "def plot_reg(test_data, pred_data, label_x, nbin, bin_range):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].hist(test_data, label='Test data', histtype='step', bins=nbin, range=bin_range)\n",
    "    ax[0].hist(pred_data, label='Prediction data', histtype='step', bins=nbin, range=bin_range)\n",
    "    ax[0].set_ylabel('counts')\n",
    "    ax[0].set_xlabel(label_x)\n",
    "    ax[0].set_yscale('log')\n",
    "    ax[0].legend()\n",
    "    \n",
    "    ax[1].hist(test_data-pred_data, bins=nbin, histtype='step')\n",
    "    ax[1].set_xlabel(r\"$\\Delta$\"+label_x)\n",
    "    # ax[1].set_yscale('log')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995725bf-fb58-4563-a488-d3316a0b55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = y_pred.squeeze().detach().numpy()\n",
    "\n",
    "np.savetxt(\"targets.csv\", np.concatenate((y_test, pred_y), axis=1), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26298231-3e87-417d-a899-dde7411350b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reg(y_test[:, 2], pred_y[:, 2], 'z [cm]', 50, [-850., 300.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ed9d7-259c-42de-9e13-0d3a491a4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reg(y_test[:, 0], pred_y[:, 0], 'x [cm]', 20, [-5., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98093c6a-a16b-4bd8-913d-8655ac752c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reg(y_test[:, 1], pred_y[:, 1], 'y [cm]', 20, [-5., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629ad5f5-10ac-4ac7-be7d-b8688fa80478",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reg(y_test[:, 3], pred_y[:, 3], 'px [GeV/c]', 20, [-5., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b34fcf-ac27-44e0-8452-af9e8c2eae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reg(y_test[:, 4], pred_y[:, 4], 'py [GeV/c]', 20, [-5., 5.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1f662c-af34-4f61-9e26-96c630e0ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reg(y_test[:, 5], pred_y[:, 5], 'pz [GeV/c]', 20, [20., 100.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9404b0cd-3730-4aeb-8484-d0b97f2d7217",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([hotid_test.T, pred_hotid.T])\n",
    "np.savetxt(\"hot_id.csv\", p.T, delimiter=\",\")\n",
    "\n",
    "q = np.concatenate((y_test, pred_y), axis=1)\n",
    "np.savetxt(\"targets.csv\", q, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da134c-450a-4387-bdf0-133af5724cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
